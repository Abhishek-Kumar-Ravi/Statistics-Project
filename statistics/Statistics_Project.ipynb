{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86212392",
   "metadata": {},
   "source": [
    "# Problem Statement 1:\n",
    "A wholesale distributor operating in different regions of Portugal has information on annual spending of several items in their stores across different regions and channels. The data consists of 440 large retailersâ€™ annual spending on 6 different varieties of products in 3 different regions (Lisbon, Oporto, Other) and across different sales channel (Hotel, Retail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa11036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729081eb",
   "metadata": {},
   "source": [
    "# Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c9b9d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Wholesale+Customers+Data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ee573a94efde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Wholesale+Customers+Data.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Wholesale+Customers+Data.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Wholesale+Customers+Data.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35dc19",
   "metadata": {},
   "source": [
    "1.1) Use methods of descriptive statistics to summarize data. Which Region and which Channel spent the most? Which Region and which Channel spent the least?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30c42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Total_Spend'] = data['Fresh']+ data['Milk']+ data['Grocery'] + data['Frozen'] + data['Detergents_Paper'] + data['Delicatessen']\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a93c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_region = data.groupby(['Region'])['Total_Spend'].sum()\n",
    "data_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d5a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_region_v1 = pd.DataFrame(data_region)\n",
    "data_region_v1.reset_index(inplace = True)\n",
    "data_region_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbd1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Region', y = 'Total_Spend', data = data_region_v1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7343c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_channel = data.groupby(['Channel'])['Total_Spend'].sum()\n",
    "data_channel_v1 = pd.DataFrame(data_channel)\n",
    "data_channel_v1.reset_index(inplace = True)\n",
    "data_channel_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4dc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x = 'Channel', y = 'Total_Spend', data = data_channel_v1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83ac08",
   "metadata": {},
   "source": [
    "From the above analysis \"Hotel\" channel spends the most while \"Retail\" spends the least.Also the total spending in \"Other\" region is high and least in the \"Oporto\" region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dda0690",
   "metadata": {},
   "source": [
    "# 1.2) There are 6 different varieties of items that are considered. Describe and comment/explain all the varieties across Region and Channel? Provide a detailed justification for your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2f6e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468eb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b = data.groupby(['Region','Channel'])[['Fresh', 'Milk', 'Grocery',\n",
    "       'Frozen', 'Detergents_Paper', 'Delicatessen']].median()\n",
    "\n",
    "data_b.reset_index(inplace = True)\n",
    "\n",
    "data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3decf8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b_median = data_b.median()\n",
    "data_b_median = pd.DataFrame(data_b_median)\n",
    "data_b_median.reset_index(inplace = True)\n",
    "data_b_median_v1 = data_b_median.rename(columns = {'index':'items', 0:'median'})\n",
    "data_b_median_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa4824",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b_mean = data.groupby(['Region','Channel'])[['Fresh', 'Milk', 'Grocery',\n",
    "       'Frozen', 'Detergents_Paper', 'Delicatessen']].mean()\n",
    "\n",
    "data_b_mean.reset_index(inplace = True)\n",
    "data_b_mean_v1 = data_b_mean.mean()\n",
    "data_b_mean_v1 = pd.DataFrame(data_b_mean_v1)\n",
    "data_b_mean_v1.reset_index(inplace = True)\n",
    "data_b_mean_v1 = data_b_mean_v1.rename(columns = {'index':'items', 0:'mean'})\n",
    "data_b_mean_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90cd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b_final = pd.merge(data_b_mean_v1,data_b_median_v1,on= ['items'])\n",
    "data_b_final['mean_value'] = data_b_final['mean'].round(decimals = 1)\n",
    "data_b_final_v1 = data_b_final.drop(['mean'] , axis = 1)\n",
    "display(data_b_final_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f4af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.barplot(x = 'items', y = 'median' , data = data_b_final_v1, hue = 'mean_value')\n",
    "plt.xticks(rotation = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53647428",
   "metadata": {},
   "source": [
    "The mean and median of all items across all channel and region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c415bc",
   "metadata": {},
   "source": [
    "From the graph it's clear that at an overall level the \"Fresh\" items are in high demand across all region and channel while \"Delicatessen\" has the lowest demand. So it will be better if company focuses more on \"Fresh\" , then followed by \"Grocery\" and \"Milk\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4db669",
   "metadata": {},
   "source": [
    "# 1.3) On the basis of a descriptive measure of variability, which item shows the most inconsistent behaviour? Which items show the least inconsistent behaviour?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77039191",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b84a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ['Fresh', 'Milk', 'Grocery','Frozen', 'Detergents_Paper', 'Delicatessen']\n",
    "data_q3 = pd.DataFrame({'product':[], 'cov': []})\n",
    "for i in items:\n",
    "    data_q3 = data_q3.append({'product' :i, 'cov': data[i].mean()/data[i].std()}, ignore_index = True)\n",
    "\n",
    "data_q4 =data_q3.round(decimals = 2)\n",
    "data_q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0cb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.figure(figsize = (10,5))\n",
    "sns.barplot(x = 'product', y = 'cov', data = data_q4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26042c",
   "metadata": {},
   "source": [
    "From the above analysis we can say that \"Fresh\" remains the most consistent item across all channel and region followed by Grocery and Milk while Delicatessen remains the least inconsistent iteam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2cc8b0",
   "metadata": {},
   "source": [
    "# 1.4) Are there any outliers in the data? Back up your answer with a suitable plot/technique with the help of detailed comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d5aac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Milk\n",
    "data['Milk'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.distplot(data['Milk']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7da918",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.boxplot(data['Milk'], showmeans = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f328ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fresh\n",
    "data['Fresh'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.distplot(data['Fresh']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdb340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.boxplot(data['Fresh'], showmeans = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grocery\n",
    "data['Grocery'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b84a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.distplot(data['Grocery']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09367c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.boxplot(data['Grocery'], showmeans = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc2945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frozen\n",
    "data['Frozen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3e9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.distplot(data['Frozen']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb9977",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.boxplot(data['Frozen'], showmeans = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58376dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detergents_Paper\n",
    "data['Detergents_Paper'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286d40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.distplot(data['Detergents_Paper']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbde3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.boxplot(data['Detergents_Paper'], showmeans = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delicatessen\n",
    "data['Delicatessen'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb914d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.distplot(data['Delicatessen']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.boxplot(data['Delicatessen'], showmeans = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d02dd9",
   "metadata": {},
   "source": [
    "Milk, Fresh and Grocery have the large number of outliers as compared to the rest three items. All items are positive schewed . So it will be better to consider median for the analysis in place of mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33409b98",
   "metadata": {},
   "source": [
    "# Problem 2:\n",
    "The Student News Service at Clear Mountain State University (CMSU) has decided to gather data about the undergraduate students that attend CMSU. CMSU creates and distributes a survey of 14 questions and receives responses from 62 undergraduates (stored in the Survey data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00786441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('survey.csv')\n",
    "data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20753ac1",
   "metadata": {},
   "source": [
    "2.1) For this data, construct the following contingency tables (Keep Gender as row variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee503ae",
   "metadata": {},
   "source": [
    "2.1.1. Gender and Major"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d3b278",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_1 = pd.crosstab(data_2['Gender'], data_2['Major'], margins = True)\n",
    "q_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a75108",
   "metadata": {},
   "source": [
    "2.1.2. Gender and Grad Intention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efbf65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data_2['Gender'], data_2['Grad Intention'], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190e4063",
   "metadata": {},
   "source": [
    "2.1.3. Gender and Employment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9acca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data_2['Gender'], data_2['Employment'], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e62fdbc",
   "metadata": {},
   "source": [
    "2.1.4. Gender and Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(data_2['Gender'], data_2['Computer'], margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a074c89",
   "metadata": {},
   "source": [
    "# 2.2. Assume that the sample is representative of the population of CMSU. Based on the data, answer the following question:\n",
    "\n",
    "2.2.1. What is the probability that a randomly selected CMSU student will be male?\n",
    "\n",
    "2.2.2. What is the probability that a randomly selected CMSU student will be female?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89644eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_A = {'Male' : [29], 'Female':[33], 'Overall':[62]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48612656",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = pd.DataFrame(data_A)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e033503f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob['Male_Probability'] = prob['Male']/prob['Overall']\n",
    "prob['Male_Probability'] = prob['Male_Probability'].round(decimals = 2)\n",
    "prob['Female_Probability'] = prob['Female']/prob['Overall']\n",
    "prob['Female_Probability'] = prob['Female_Probability'].round(decimals = 2)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b547967",
   "metadata": {},
   "source": [
    "# 2.3. Assume that the sample is representative of the population of CMSU. Based on the data, answer the following question:\n",
    "\n",
    "2.3.1. Find the conditional probability of different majors among the male students in CMSU.\n",
    "\n",
    "2.3.2 Find the conditional probability of different majors among the female students of CMSU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de643bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3 = data_2[data_2['Gender'] == 'Male'][['Gender','Major']]\n",
    "data_4 = data_3.groupby(['Major'])['Gender'].count()\n",
    "data_4 = pd.DataFrame(data_4)\n",
    "data_4 = data_4.reset_index()\n",
    "data_4 = data_4.rename(columns = {'Gender': 'Male'})\n",
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4['Probability_Male'] = data_4['Male']/data_4['Male'].sum()\n",
    "data_4 = data_4.round(decimals = 2)\n",
    "data_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f49259",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Female\n",
    "data_5 = data_2[data_2['Gender'] == 'Female'][['Gender','Major']]\n",
    "data_6 = data_5.groupby(['Major'])['Gender'].count()\n",
    "data_6 = pd.DataFrame(data_6)\n",
    "data_6 = data_6.reset_index()\n",
    "data_6 = data_6.rename(columns = {'Gender': 'Female'})\n",
    "data_6['Probability_Female'] = data_6['Female']/data_6['Female'].sum()\n",
    "data_6 = data_6.round(decimals = 2)\n",
    "data_6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48008ce",
   "metadata": {},
   "source": [
    "# 2.4. Assume that the sample is a representative of the population of CMSU. Based on the data, answer the following question:\n",
    "\n",
    "2.4.1. Find the probability That a randomly chosen student is a male and intends to graduate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c38424",
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = data_2['Gender'][(data_2['Gender'] == 'Male') & (data_2['Grad Intention'] == 'Yes')].count()/data_2['Gender'].count()\n",
    "probability = probability.round(decimals = 2)\n",
    "probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##2.4.2 Find the probability that a randomly selected student is a female and does NOT have a laptop.\n",
    "probability_1 = data_2['Gender'][(data_2['Gender'] == 'Female') & (data_2['Computer'] != 'Laptop')].count()/data_2['Gender'].count()\n",
    "probability_1 = probability_1.round(decimals = 2)\n",
    "probability_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ef3b8",
   "metadata": {},
   "source": [
    "# 2.5. Assume that the sample is representative of the population of CMSU. Based on the data, answer the following question:\n",
    "\n",
    "2.5.1. Find the probability that a randomly chosen student is a male or has full-time employment?\n",
    "\n",
    "2.5.2. Find the conditional probability that given a female student is randomly chosen, she is majoring in international business or management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082902d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the probability that a randomly chosen student is a male or has full-time employment?\n",
    "\n",
    "probability_2 = data_2['Gender'][(data_2['Gender'] == 'Male') | (data_2['Employment'] == 'Full-Time')].count()/data_2['Gender'].count()\n",
    "probability_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65c8480",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the conditional probability that given a female student is randomly chosen, she is majoring in international business or management.\n",
    "\n",
    "probability_4 = data_2['Gender'][(data_2['Gender'] == 'Female') & ((data_2['Major'] == 'International Business') | (data_2['Major'] == 'Management'))].count()/data_2['Gender'][data_2['Gender'] == 'Female'].count()\n",
    "probability_4 = probability_4.round(decimals = 2)\n",
    "probability_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07dbce",
   "metadata": {},
   "source": [
    "# 2.6. Construct a contingency table of Gender and Intent to Graduate at 2 levels (Yes/No). The Undecided students are not considered now and the table is a 2x2 table. Do you think the graduate intention and being female are independent events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cd985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_10 = data_2[['Gender', 'Grad Intention']]\n",
    "data_11 = data_10.replace(to_replace = 'Undecided', value = 'No')\n",
    "data_12 = pd.crosstab(data_11['Gender'], data_11['Grad Intention'], margins = True)\n",
    "data_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a984f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Do you think the graduate intention and being female are independent events?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebdb329",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_graduation = data_11['Grad Intention'][data_11['Grad Intention'] == 'Yes'].count()/data_11['Grad Intention'].count()\n",
    "prob_graduation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e930ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_female = data_11['Gender'][data_11['Gender'] == 'Female'].count()/data_11['Gender'].count()\n",
    "prob_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a31ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_graduation*prob_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6aea7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_female_graduation = data_11['Grad Intention'][(data_11['Grad Intention'] == 'Yes')&(data_11['Gender'] == 'Female')].count()/data_11['Grad Intention'].count()\n",
    "prob_female_graduation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366fd8e",
   "metadata": {},
   "source": [
    "For independent event prob_female * prob_graduation should be equal to prob_female_graduation.\n",
    "Here this condition is not satisfied so it is not an independent event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c5f536",
   "metadata": {},
   "source": [
    "# 2.7. Note that there are four numerical (continuous) variables in the data set, GPA, Salary, Spending, and Text Messages.\n",
    "\n",
    "Answer the following questions based on the data\n",
    "\n",
    "2.7.1. If a student is chosen randomly, what is the probability that his/her GPA is less than 3?\n",
    "\n",
    "2.7.2. Find the conditional probability that a randomly selected male earns 50 or more. Find the conditional probability that a randomly selected female earns 50 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If a student is chosen randomly, what is the probability that his/her GPA is less than 3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268f2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd134eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_gpa = data_2['Gender'][data_2['GPA'] < 3].count()/data_2['Gender'].count()\n",
    "a = prob_gpa.round(decimals = 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ddb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the conditional probability that a randomly selected male earns 50 or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbee29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_earn = data_2['Gender'][(data_2['Gender'] == 'Male') & (data_2['Salary'] >= 50.0)].count()/data_2['Gender'].count()\n",
    "b = prob_earn.round(decimals = 2)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3075da",
   "metadata": {},
   "source": [
    "# 2.8. Note that there are four numerical (continuous) variables in the data set, GPA, Salary, Spending, and Text Messages. For each of them comment whether they follow a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2['Salary'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f50a754",
   "metadata": {},
   "source": [
    " Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef8eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2['GPA'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae096433",
   "metadata": {},
   "source": [
    "Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0f69a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2['Salary'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f89a6",
   "metadata": {},
   "source": [
    "Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2['Spending'].skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0642b1",
   "metadata": {},
   "source": [
    "Positive Skew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa858d",
   "metadata": {},
   "source": [
    "# Third Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab191e44",
   "metadata": {},
   "source": [
    "An important quality characteristic used by the manufacturers of ABC asphalt shingles is the amount of moisture the shingles contain when they are packaged. Customers may feel that they have purchased a product lacking in quality if they find moisture and wet shingles inside the packaging.   In some cases, excessive moisture can cause the granules attached to the shingles for texture and colouring purposes to fall off the shingles resulting in appearance problems. To monitor the amount of moisture present, the company conducts moisture tests. A shingle is weighed and then dried. The shingle is then reweighed, and based on the amount of moisture taken out of the product, the pounds of moisture per 100 square feet is calculated. The company would like to show that the mean moisture content is less than 0.35 pound per 100 square feet.\n",
    "\n",
    "The file (A & B shingles.csv) includes 36 measurements (in pounds per 100 square feet) for A shingles and 31 for B shingles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110c2798",
   "metadata": {},
   "source": [
    "3.1 Do you think there is evidence that means moisture contents in both types of shingles are within the permissible limits? State your conclusions clearly showing all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004a71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3q = pd.read_csv('data_3.csv')\n",
    "data_3q.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e432e77a",
   "metadata": {},
   "source": [
    "##There are 5 null values in column B. So to keep them in data but not considering for analysis we are using scipy library and since both columns are independent we are using independent t test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69c884",
   "metadata": {},
   "source": [
    "Ho : Mean moisture of both shingles are within permissible limit i.e mean is less than or equal to 0.35 pound\n",
    "\n",
    "H1 : Mean moisture of both shingles are greater than 0.35 pound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4771a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "t,p = ss.ttest_ind(data_3q['A'], data_3q['B'],nan_policy = 'omit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dcac3a",
   "metadata": {},
   "source": [
    "Since it is a one side test so if p/2 is greater than 0.05 then null hypothesis is accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751d9dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694f510e",
   "metadata": {},
   "source": [
    "we failed to reject null hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575f3923",
   "metadata": {},
   "source": [
    "Do you think that the population mean for shingles A and B are equal? Form the hypothesis and conduct the test of the hypothesis. What assumption do you need to check before the test for equality of means is performed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1d57a",
   "metadata": {},
   "source": [
    "Ho : Population mean of both shingles are equal\n",
    "\n",
    "H1 : Polulation mean of both shingles are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4617663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "t,p = ss.ttest_ind(data_3q['A'], data_3q['B'],nan_policy = 'omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6deda",
   "metadata": {},
   "source": [
    "Here the t-test is two sided so whatever we get the output, if the p value is greater than 0.05 then null hypothesis is accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dcc0f3",
   "metadata": {},
   "source": [
    "so null hypothesis is accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66966b",
   "metadata": {},
   "source": [
    "What assumption do you need to check before the test for equality of means is performed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd473f15",
   "metadata": {},
   "source": [
    "Independence: The observations in one sample are independent of the observations in the other sample.\n",
    "\n",
    "Normality: Both samples are approximately normally distributed.\n",
    "\n",
    "Homogeneity of Variances: Both samples have approximately the same variance.\n",
    "\n",
    "Random Sampling: Both samples were obtained using a random sampling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f35a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
